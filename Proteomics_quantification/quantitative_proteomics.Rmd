---
title: "Analysis of Quantitative Proteomics Data"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The result of a proteomic quantitative analysis is a list of peptide and protein abundances for every protein in different samples, or abundance ratios between the samples. The downstream interpretation varies according to the experimental design. In this chapter we will describe different generic methods for the interpretation of quantitative datasets.

## Identification and Quantification

The analysis of the raw data yielding the quantitative information constitutes an entire course in itself and is not detailed here. Many bioinformatic environments allow the processing of proteomics data, each coming with specific features and different levels of user friendliness. An inexhaustive list is provided in the table below.

| Tool | Usage | Comment |
| ---- | ----- | ------- |
| [MaxQuant](maxquant.org) | Untargeted quantification | Tools for quantificaion and post-processing of untargeted proteomics data. |
| [Skyline](https://skyline.ms/project/home/software/Skyline/begin.view) | Targeted quantification | Tool for targeted proteomics and metabolomics. |
| [OpenMS](https://www.openms.de/) | Bioinformatic pipeline | Suite of tools for proteomics and metabolomics that can be chained to build pipelines. |
| [TPP](http://tools.proteomecenter.org) | Bioinformatic pipeline | Suite of tools for proteomics that can be chained to build pipelines. |

MaxQuant [(1)](#references) and Skyline [(2)](#references) are reference tools for the analysis of untargeted and targeted proteomics data, respectively. Both tools provide extensive educational material and are the place to start for beginners. We highly recommend attending their courses.


## Data

The dataset used for this tutorial is the same as in the _Proteomics Data_ chapter. It is freely available through the ProteomeXchange [(3)](#references) consortium via the PRIDE [(4)](#references) partner repository under the accession number PXD000441.

Briefly, the authors spiked a mix of proteins called the Universal Proteomics Standard (UPS) in a background of yeast proteins. The UPS proteins are spiked at different concentrations between samples while the yeast proteins stay the same. The summary table of the quantification results is available in the [resources](resources/Supplementary Table 1.xlsx) folder.

:speech_balloon: _What is shown in row/columns in the file?_


## Github

It has become good practice to share data, code and documentation related to scientific projects. Github is a collaborative environment that is based around the git versioning system.

:pencil2: Go to the tutorial repository [github.com/FaroePracticalBioinformatics/tutorials18](https://github.com/FaroePracticalBioinformatics/tutorials18) and click on `Fork`.

This will create a copy of the repository to you own Github space. You can then work on the code by yourself and make changes. You can also submit you changes to the main repository via a `Pull Request`.

:pencil2: In your Github repository, copy the URL available under _Clone or download_.


## Tools

While we could process this data set in Excel, this would limit us in terms of what we can do with the data, and it does not scale to larger experiments. Modern data interpretation is done programmatically. It takes time and frustration to get acquainted with this different paradigm, but you will quickly reach a point where you can do much better much faster. Several languages and frameworks make this possible, the most encountered are Python, R, Matlab, and Mathematica. They can be used in command line or via user interfaces. Recently, notebooks mixing code and comments gained popularity for their ability to combine documentation and reproducibility. Also, note that Perseus, the compagnon tool of MaxQuant allows processing large omics data sets in a graphical environment.

This tutorial uses [R](https://www.r-project.org), a language that allows the simple manipulation of large datasets. We will use R from the open source [RSudio](www.rstudio.com) environment. Please make sure to have RStudio installed on your computer.

:pencil2: Create a new project via the _File_ -> _New Projet_ menu. Select _Version Control_ and put the URL to the repository copied previously.

You now have an image of the repository on your computer that is synchronized with the version in Github.

The commands used in this tutorial are given in line and the results produced are preceded by `##`. You can copy the commands of this tutorial in your script, where one line corresponds to a command. The commands can be run line by line using the _Run_ button. Alternatively, you can run the entire script using the _Source_ button. Note that it is also possible to run the commands in the _Console_.

We are going to use the [ggplot2](http://ggplot2.org/) library. If you did not install this package already, install it usng the _Packages_ tab or run `install.packages("ggplot2")`.

```{r libraries}

library(ggplot2)

```

_ggplot2_ has different themes for display, we are not going to use the default and instead set a theme for the whole project.

```{r ggplot2_theme}

theme_set(theme_bw(base_size = 11))

```




## File import

Most software output text files that can readily be imported in R as data frame. A data frame is a representation of a table just like an Excel sheet. The table used in our analysis is 

```{r input}

proteinGroupsInput <- read.table(file = "resources/mq.txt", header = T, stringsAsFactors = F, sep = "\t")

```

You should see the `proteinGroupsInput` in your _Environment_ panel. You can view the file using the `View` command.

```{r input_size}

View(proteinGroupsInput)

```

You can look at how many background (yeast) and spiked (UPS) proteins are found using the `table` function.

```{r species}

table(proteinGroupsInput$Species)

```

The columns with quantitative information are indicated as A1, A2, A3, B1, B2, and B3, where A and B represent the different conditions of the first column and 1, 2, and, 3 biological replicates. You can look at the distribution of intensities using the `hist` function. First, concatenate all intensities in a vector.

```{r concat}

allIntensities <- c(
    proteinGroupsInput$A1,
    proteinGroupsInput$A2,
    proteinGroupsInput$A3,
    proteinGroupsInput$B1,
    proteinGroupsInput$B2,
    proteinGroupsInput$B3
)

```

Then, simply call the hist function.

```{r hist}

hist(allIntensities)

```

As you can see, most of the intensities are on the lower side of the x axis. Plotting the histogram of the log will allow us to see how the order of magnitude of the intensities distribute.

```{r histLog}

hist(log10(allIntensities))

```

We now create log values of the intensities, and whenever we will work on the intensities in column, we will use the log values.

```{r log}

    proteinGroupsInput$A1_log <- log10(proteinGroupsInput$A1)
    proteinGroupsInput$A2_log <- log10(proteinGroupsInput$A2)
    proteinGroupsInput$A3_log <- log10(proteinGroupsInput$A3)
    proteinGroupsInput$B1_log <- log10(proteinGroupsInput$B1)
    proteinGroupsInput$B2_log <- log10(proteinGroupsInput$B2)
    proteinGroupsInput$B3_log <- log10(proteinGroupsInput$B3)

```

In the following, we are going to use the `ggplot2` package to build plots. It is a powerful data visualization library that will allow us getting a better understanding of the data.

The first step is to organize our data in a data frame with a single column contaning all the values to plot, and covariates in other columns.

```{r df}

nProteins <- nrow(proteinGroupsInput)

intensitiesDF <- data.frame(
    intensity = c(
        proteinGroupsInput$A1_log,
        proteinGroupsInput$A2_log,
        proteinGroupsInput$A3_log,
        proteinGroupsInput$B1_log,
        proteinGroupsInput$B2_log,
        proteinGroupsInput$B3_log
    ),
    sample = c(
        rep("A1", nProteins),
        rep("A2", nProteins),
        rep("A3", nProteins),
        rep("B1", nProteins),
        rep("B2", nProteins),
        rep("B3", nProteins)
    ),
    condition = c(
        rep("A", nProteins),
        rep("A", nProteins),
        rep("A", nProteins),
        rep("B", nProteins),
        rep("B", nProteins),
        rep("B", nProteins)
    ),
    replicate = c(
        rep("1", nProteins),
        rep("2", nProteins),
        rep("3", nProteins),
        rep("1", nProteins),
        rep("2", nProteins),
        rep("3", nProteins)
    )
)

View(intensitiesDF)

```

Now we will build the histogram using the `geom_histogram` function and plot using the default `plot` function.

```{r geom_hist}

histogram <- ggplot() + geom_histogram(data = intensitiesDF, mapping = aes(x = intensity), bins = 20, na.rm = T)

plot(histogram)

```

:speech_balloon: _Do you expect the different samples to display similar intensity distributions?_

You can easily plot the different samples separately by using the `facet_grid` function.

```{r facet_grid}

histogram <- ggplot() + 
    geom_histogram(data = intensitiesDF, mapping = aes(x = intensity), bins = 20, na.rm = T) +
    facet_grid(condition ~ replicate)

plot(histogram)

```

:pencil2: Can you plot the density instead of a histogram?

A very useful way to visualize quantitative distributions is to make box plots. This can be done using the `geom_boxplot` function.

```{r facet_grid}

boxPlot <- ggplot() + 
    geom_boxplot(data = intensitiesDF, mapping = aes(x = sample, y = intensity), na.rm = T)

plot(boxPlot)

```

[:thought_balloon:6](../Answers.md#thought_balloon6) _What is represented by a box plot?_

Similarly, you can display the density as _violin plot_ using the function `geom_violin`.

```{r geom_violin}

violinPlot <- ggplot() + 
    geom_violin(data = intensitiesDF, mapping = aes(x = sample, y = intensity), na.rm = T)

plot(violinPlot)

```

Note that it is possible to overlay geometries in ggplot.

```{r overlay}

violinPlot <- ggplot() + 
    geom_violin(data = intensitiesDF, mapping = aes(x = sample, y = intensity), na.rm = T) +
    geom_boxplot(data = intensitiesDF, mapping = aes(x = sample, y = intensity), width = 0.5, na.rm = T)

plot(violinPlot)

```


## Missing values filtering

As you might have noticed, in the previous plots we removed missing values indicated by _NA_ using `na.rm = T`. You can find them with the `is.na` function.

```{r NAs}

print("A1")
sum(is.na(proteinGroupsInput$A1))

print("A2")
sum(is.na(proteinGroupsInput$A2))

print("A3")
sum(is.na(proteinGroupsInput$A3))

print("B1")
sum(is.na(proteinGroupsInput$B1))

print("B2")
sum(is.na(proteinGroupsInput$B2))

print("B3")
sum(is.na(proteinGroupsInput$B3))

```

:speech_balloon: _Where do missing values come from? Do you see different patterns between samples? How should we handle this?_

In this tutorial, we will allow only one missing value in each condition. The following code counts the number of missing values in _A_ samples and makes a new data frame with max one missing value among _A_ samples.

```{r NA_A}

aValues <- proteinGroupsInput[, c("A1", "A2", "A3")]
aNA <- apply(X = aValues, FUN = is.na, MARGIN = c(1, 2))
aNaSum <- apply(X = aNA, FUN = sum, MARGIN = 1)

proteinGroupsAfiltered <- proteinGroupsInput[aNaSum <= 1, ]

print(paste0("# proteins excluded: ", nrow(proteinGroupsInput) - nrow(proteinGroupsAfiltered)))

```

:pencil2: Do the same for condition _B_ and save the result in a data frame called `proteinGroupsNaFiltered`.

We can check the number of missing values in each condition using the `table` function again.

```{r NA_table}

aValues <- proteinGroupsNaFiltered[, c("A1", "A2", "A3")]
aNA <- apply(X = aValues, FUN = is.na, MARGIN = c(1, 2))
aNaSum <- apply(X = aNA, FUN = sum, MARGIN = 1)

bValues <- proteinGroupsNaFiltered[, c("B1", "B2", "B3")]
bNA <- apply(X = bValues, FUN = is.na, MARGIN = c(1, 2))
bNaSum <- apply(X = bNA, FUN = sum, MARGIN = 1)

allValues <- cbind(aValues, bValues)
allNA <- apply(X = allValues, FUN = is.na, MARGIN = c(1, 2))
allNaSum <- apply(X = allNA, FUN = sum, MARGIN = 1)

print("# protein with missing values in A: ")
table(aNaSum)

print("# protein with missing values in B: ")
table(bNaSum)

print("# protein with missing values: ")
table(allNaSum)


```


## Missing values imputation

Many analysis methods do not support missing values, we are going to make a new data frame where missing values are imputed. Here, we hypothesize that missing values are due to proteins being below the level of quantification. We will therefore impute missing values to an arbitrarily low value.

:speech_balloon: _Can you think of another way to impute missing values?_

In the following code, we create a function that replaces NAs with random values generated from a normal distribution under an arbitrary level using the `rnorm` function.

```{r imputation_function}

impute <- function(value, mean, sd, limit) {
    
    if (!is.na(value)) {
        return(value)
    }
    
    while (T) {
        
        
        result <- rnorm(1, mean = mean, sd = sd)
        
        if (result < limit) {
            
            return(result)
            
        }   
    }
    
    return(NA)
    
}


```

We then create new columns with imputed missing values.

```{r imputation}

for (column in c("A1", "A2", "A3", "B1", "B2", "B3")) {
    
    logCol <- paste0(column, "_log")
    imputedCol <- paste0(column, "_imputed")
    imputedLogCol <- paste0(logCol, "_imputed")
    
    mean <- mean(proteinGroupsNaFiltered[, logCol], na.rm = T)
    sd <- sd(proteinGroupsNaFiltered[, logCol], na.rm = T)
    limit <- min(proteinGroupsNaFiltered[, logCol], na.rm = T)
    
    proteinGroupsNaFiltered[, imputedLogCol] <- sapply(X = proteinGroupsNaFiltered[, logCol], FUN = impute, mean = mean, sd = sd, limit = limit)
    
    proteinGroupsNaFiltered[, imputedCol] <- 10 ^ proteinGroupsNaFiltered[, imputedLogCol]
    
}


```

:speech_balloon: _Why is the imputation done using the log values?_

Let's look at the distribution of values now using different colors for imputed values.

```{r imputed_distribution}

# Make a data frame of values to plot

nProteins <- nrow(proteinGroupsNaFiltered)

intensitiesDF <- data.frame(
    intensity = c(
        proteinGroupsNaFiltered$A1_log_imputed,
        proteinGroupsNaFiltered$A2_log_imputed,
        proteinGroupsNaFiltered$A3_log_imputed,
        proteinGroupsNaFiltered$B1_log_imputed,
        proteinGroupsNaFiltered$B2_log_imputed,
        proteinGroupsNaFiltered$B3_log_imputed
    ),
    sample = c(
        rep("A1", nProteins),
        rep("A2", nProteins),
        rep("A3", nProteins),
        rep("B1", nProteins),
        rep("B2", nProteins),
        rep("B3", nProteins)
    ),
    condition = c(
        rep("A", nProteins),
        rep("A", nProteins),
        rep("A", nProteins),
        rep("B", nProteins),
        rep("B", nProteins),
        rep("B", nProteins)
    ),
    replicate = c(
        rep("1", nProteins),
        rep("2", nProteins),
        rep("3", nProteins),
        rep("1", nProteins),
        rep("2", nProteins),
        rep("3", nProteins)
    ),
    imputed = c(
        is.na(proteinGroupsNaFiltered$A1_log),
        is.na(proteinGroupsNaFiltered$A2_log),
        is.na(proteinGroupsNaFiltered$A3_log),
        is.na(proteinGroupsNaFiltered$B1_log),
        is.na(proteinGroupsNaFiltered$B2_log),
        is.na(proteinGroupsNaFiltered$B3_log)
    )
)


# Build plot

histogram <- ggplot() + 
    geom_histogram(data = intensitiesDF, mapping = aes(x = intensity, fill = imputed), bins = 20) +
    facet_grid(condition ~ replicate)


# Plot

plot(histogram)



```

:speech_balloon: _What do you think of our imputation function?_

## Extraction of the quantitative columns

The expression values of the five cell lines used are stored in different columns as detailed below. They correspond to two states of the disease, _Diagnosis_ and _Relapse_.

Column | Cell Line | Condition
------ | --------- | ---------
Ratio H/L normalized E1 | Molm-13 | Relapse
Ratio H/L normalized E2 | MV4-11 | Diagnosis
Ratio H/L normalized E3 | NB4 | Relapse
Ratio H/L normalized E4 | OCI-AML3 | Diagnosis
Ratio H/L normalized E5 | THP-1 | Relapse

Note that when importing the data in R, spaces and special characters in the column titles were replaces by dots.

We will now store these values in a new table and save the columns of the cell lines at different conditions in two vectors.

```{r ratios_extraction}
proteinGroupsRatios <- data.frame(proteinIDs = proteinGroups$Protein.IDs, 
                     molm13 = proteinGroups$Ratio.H.L.normalized.E1, 
                     mv411 = proteinGroups$Ratio.H.L.normalized.E2,
                     nb4 = proteinGroups$Ratio.H.L.normalized.E3,
                     ociAml3 = proteinGroups$Ratio.H.L.normalized.E4,
                     thp1 = proteinGroups$Ratio.H.L.normalized.E5)
diagnosisCellLines <- c("mv411", "ociAml3")
relapseCellLines <- c("molm13", "nb4", "thp1")
```

The ratios can be plotted against each others for different cell lines in a scatter plot using the code below.

```{r scatter_plot}
cellLineX <- "mv411"
cellLineY <- "ociAml3"
scatterPlot <- ggplot()
scatterPlot <- scatterPlot + geom_point(aes(x=proteinGroupsRatios[,cellLineX], y=proteinGroupsRatios[,cellLineY]), alpha=0.2, col="blue", size=1, na.rm = T)
scatterPlot <- scatterPlot + xlab(cellLineX) + ylab(cellLineY)
plot(scatterPlot)
```

It is possible to extract the ratios of a given protein.

```{r A0FGR8_ratios}
proteinGroupsRatios[proteinGroupsRatios$proteinIDs == "A0FGR8",]
```

It is possible to extract the ratios of a given protein for a given condition.

```{r A0FGR8_diagnosis_ratios}
proteinGroupsRatios[proteinGroupsRatios$proteinIDs == "A0FGR8", names(proteinGroupsRatios) %in% diagnosisCellLines]
```

Note that some proteins have missing values.

```{r A0JLT2_ratios}
proteinGroupsRatios[proteinGroupsRatios$proteinIDs == "A0JLT2",]
```


## Filtering based on the number of missing values

It is possible to see whether a value is missing using the is.na function.

```{r A0JLT2_missing}
is.na(proteinGroupsRatios[proteinGroupsRatios$proteinIDs == "A0JLT2",])
```

The number of missing values for a condition can be obtained with the sum function.

```{r A0JLT2_n_missing}
sum(is.na(proteinGroupsRatios[proteinGroupsRatios$proteinIDs == "A0JLT2", names(proteinGroupsRatios) %in% diagnosisCellLines]))
```

Filter the ratio table to have at least two valid values in every conition, i.e. no missing value at diagnosis and maximum one at relapse. Doing the sum on every row is done using rowSums.

```{r filter_valid_values}
nMissingDiagnosis <- rowSums(is.na(proteinGroupsRatios[, names(proteinGroupsRatios) %in% diagnosisCellLines]))
nMissingRelapse <- rowSums(is.na(proteinGroupsRatios[, names(proteinGroupsRatios) %in% relapseCellLines]))
validProteinGroupsRatios <- proteinGroupsRatios[nMissingDiagnosis == 0 & nMissingRelapse <= 1,]

nLines <- length(validProteinGroupsRatios$proteinIDs)
nFiltered <- length(proteinGroupsRatios$proteinIDs) - length(validProteinGroupsRatios$proteinIDs)
paste("New number of protein groups: ", nLines, ", Number of protein groups removed: ", nFiltered, sep="")
```

The number of protein presenting missing values can be plotted using the code below.

```{r plot_missing_values_histogram}
categoryDiagnosis <- character(length(nMissingDiagnosis))
categoryDiagnosis[] <- "Diagnosis"
categoryRelapse <- character(length(nMissingRelapse))
categoryRelapse[] <- "Relapse"
categories <- c(categoryDiagnosis, categoryRelapse)
values <- c(nMissingDiagnosis, nMissingRelapse)

missingValuesHistogramPlot <- ggplot()
missingValuesHistogramPlot <- missingValuesHistogramPlot + geom_bar(aes(x=values, fill=categories), position = "dodge")
missingValuesHistogramPlot <- missingValuesHistogramPlot + xlab("Number of missing values") + ylab("Number of proteins")
plot(missingValuesHistogramPlot)
```

## Transformation of the ratios

The MaxQuant ratios are estimated as _Heavy/Light_, but our reference was on the _Heavy_ channel, we therefore need to invert the ratios in order to obtain a value representing the cell line to internal standard ratio.

```{r ratio_inversion}
validProteinGroupsRatios[,"molm13"] <- 1/validProteinGroupsRatios[,"molm13"]
validProteinGroupsRatios[,"mv411"] <- 1/validProteinGroupsRatios[,"mv411"]
validProteinGroupsRatios[,"nb4"] <- 1/validProteinGroupsRatios[,"nb4"]
validProteinGroupsRatios[,"ociAml3"] <- 1/validProteinGroupsRatios[,"ociAml3"]
validProteinGroupsRatios[,"thp1"] <- 1/validProteinGroupsRatios[,"thp1"]
```

As one can see, the ratios are distributed over positive values around 1.

```{r ratio_densities}
categories <- c()
categoryCellLine <- character(length(validProteinGroupsRatios[,"molm13"]))
categoryCellLine[] <- "molm13"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"mv411"]))
categoryCellLine[] <- "mv411"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"nb4"]))
categoryCellLine[] <- "nb4"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"ociAml3"]))
categoryCellLine[] <- "ociAml3"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"thp1"]))
categoryCellLine[] <- "thp1"
categories <- c(categories, categoryCellLine)
values <- c(validProteinGroupsRatios[,"molm13"],
            validProteinGroupsRatios[,"mv411"],
            validProteinGroupsRatios[,"nb4"],
            validProteinGroupsRatios[,"ociAml3"],
            validProteinGroupsRatios[,"thp1"])
ratiosDensityPlot <- ggplot()
ratiosDensityPlot <- ratiosDensityPlot + geom_density(aes(x=values, col=categories, fill = categories), alpha = 0.1, na.rm=TRUE)
ratiosDensityPlot <- ratiosDensityPlot + xlim(0, 5)
ratiosDensityPlot <- ratiosDensityPlot + xlab("Ratio") + ylab("Density of proteins")
plot(ratiosDensityPlot)
```

Before further processing, we log transform these ratios to restore the symmetry around 1.

```{r ratio_log}
validProteinGroupsRatios[,"molm13"] <- log2(validProteinGroupsRatios[,"molm13"])
validProteinGroupsRatios[,"mv411"] <- log2(validProteinGroupsRatios[,"mv411"])
validProteinGroupsRatios[,"nb4"] <- log2(validProteinGroupsRatios[,"nb4"])
validProteinGroupsRatios[,"ociAml3"] <- log2(validProteinGroupsRatios[,"ociAml3"])
validProteinGroupsRatios[,"thp1"] <- log2(validProteinGroupsRatios[,"thp1"])
```

Now the distributions are centered around 0 and the ratios symmetrically distributed.

```{r ratio_log_densities}
categories <- c()
categoryCellLine <- character(length(validProteinGroupsRatios[,"molm13"]))
categoryCellLine[] <- "molm13"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"mv411"]))
categoryCellLine[] <- "mv411"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"nb4"]))
categoryCellLine[] <- "nb4"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"ociAml3"]))
categoryCellLine[] <- "ociAml3"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"thp1"]))
categoryCellLine[] <- "thp1"
categories <- c(categories, categoryCellLine)
values <- c(validProteinGroupsRatios[,"molm13"],
            validProteinGroupsRatios[,"mv411"],
            validProteinGroupsRatios[,"nb4"],
            validProteinGroupsRatios[,"ociAml3"],
            validProteinGroupsRatios[,"thp1"])
ratiosDensityPlot <- ggplot()
ratiosDensityPlot <- ratiosDensityPlot + geom_density(aes(x=values, col=categories, fill = categories), alpha = 0.1, na.rm=TRUE)
ratiosDensityPlot <- ratiosDensityPlot + xlab("Ratio") + ylab("Density of proteins")
plot(ratiosDensityPlot)
```

## Normalization of the ratios

The ratios provided by MaxQuant are already normalized, but it can be useful to conduct an additional normalization to correct for eventual biases. Note: Don't forget to exclude missing values.

```{r ratio_normalization}
cellLineMedian <- median(validProteinGroupsRatios[,"molm13"], na.rm = T)
validProteinGroupsRatios[,"molm13"] <- validProteinGroupsRatios[,"molm13"] - cellLineMedian
cellLineMedian <- median(validProteinGroupsRatios[,"mv411"], na.rm = T)
validProteinGroupsRatios[,"mv411"] <- validProteinGroupsRatios[,"mv411"] - cellLineMedian
cellLineMedian <- median(validProteinGroupsRatios[,"nb4"], na.rm = T)
validProteinGroupsRatios[,"nb4"] <- validProteinGroupsRatios[,"nb4"] - cellLineMedian
cellLineMedian <- median(validProteinGroupsRatios[,"ociAml3"], na.rm = T)
validProteinGroupsRatios[,"ociAml3"] <- validProteinGroupsRatios[,"ociAml3"] - cellLineMedian
cellLineMedian <- median(validProteinGroupsRatios[,"thp1"], na.rm = T)
validProteinGroupsRatios[,"thp1"] <- validProteinGroupsRatios[,"thp1"] - cellLineMedian
```

Removing the median put the center of the distributions at 0.

```{r ratio_log_densities_normalized}
categories <- c()
categoryCellLine <- character(length(validProteinGroupsRatios[,"molm13"]))
categoryCellLine[] <- "molm13"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"mv411"]))
categoryCellLine[] <- "mv411"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"nb4"]))
categoryCellLine[] <- "nb4"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"ociAml3"]))
categoryCellLine[] <- "ociAml3"
categories <- c(categories, categoryCellLine)
categoryCellLine <- character(length(validProteinGroupsRatios[,"thp1"]))
categoryCellLine[] <- "thp1"
categories <- c(categories, categoryCellLine)
values <- c(validProteinGroupsRatios[,"molm13"],
            validProteinGroupsRatios[,"mv411"],
            validProteinGroupsRatios[,"nb4"],
            validProteinGroupsRatios[,"ociAml3"],
            validProteinGroupsRatios[,"thp1"])
ratiosDensityPlot <- ggplot()
ratiosDensityPlot <- ratiosDensityPlot + geom_density(aes(x=values, col=categories, fill = categories), alpha = 0.1, na.rm=TRUE)
ratiosDensityPlot <- ratiosDensityPlot + xlab("Ratio") + ylab("Density of proteins")
plot(ratiosDensityPlot)
```

## t-test

We are going to evaluate the significance of the ratio between the two groups using a t-test. This example does not have sufficient number of replicates to draw any biological conclusion but this is just an example. Below is an example using A0FGR8.

```{r t-test_A0FGR8}
valuesDiagnostic <- validProteinGroupsRatios[validProteinGroupsRatios$proteinIDs == "A0FGR8", names(validProteinGroupsRatios) %in% diagnosisCellLines]
valuesRelapse <- validProteinGroupsRatios[validProteinGroupsRatios$proteinIDs == "A0FGR8", names(validProteinGroupsRatios) %in% relapseCellLines]
t.test(valuesDiagnostic, valuesRelapse, alternative = "two.sided", paired = F)
```

Note that the test run is actually a Welch Two Sample t-test, an extension of the Student t-test more reliable for samples of unequal variances. We create new columns containing the test statistics, as well as the fold change and -10log(p-value).

```{r t-test}
pValues <- c()
ts <- c()
fcs <- c()
pLog <- c()
for (i in 1:length(validProteinGroupsRatios$proteinIDs)) {
  valuesDiagnostic <- validProteinGroupsRatios[i, names(validProteinGroupsRatios) %in% diagnosisCellLines]
  valuesRelapse <- validProteinGroupsRatios[i, names(validProteinGroupsRatios) %in% relapseCellLines]
  test <- t.test(valuesDiagnostic, valuesRelapse, alternative = "two.sided", paired = F)
  pValues <- c(pValues, test$p.value)
  pLog <- c(pLog, -log10(test$p.value))
  ts <- c(ts, test$statistic)
  medianDiagnostic <- median(as.numeric(valuesDiagnostic), na.rm = T)
  medianRelapse <- median(as.numeric(valuesRelapse), na.rm = T)
  fc <- medianRelapse-medianDiagnostic
  fcs <- c(fcs, fc)
}
validProteinGroupsRatios$fc <- fcs
validProteinGroupsRatios$tTestPValue <- pValues
validProteinGroupsRatios$tTestPValueLog <- pLog
validProteinGroupsRatios$tTestStatistic <- ts
```

## QQ Plot

We will now see whether the t-test statistics actually follow a t-distribution. This is achieved by drawing a quantile-quantile plot (qq-plot) where the quantile of the observed t-statistics is plotted against the theoretical quantiles of the Student t distribution.

```{r qq_plot}

degreesOfFreedom <- 5-2 # 5 cell lines

expectedQuantiles <- rt(length(validProteinGroupsRatios$tTestStatistic), df=degreesOfFreedom)
expectedQuantiles <- sort(expectedQuantiles)
measuredQuantiles <- validProteinGroupsRatios$tTestStatistic
measuredQuantiles <- sort(measuredQuantiles)

qqPlot <- ggplot()
qqPlot <- qqPlot + geom_point(aes(x=expectedQuantiles, y=measuredQuantiles), size = 1, col = "blue")
qqPlot <- qqPlot + geom_line(aes(x=expectedQuantiles, y=expectedQuantiles), size = 1, alpha = 0.5, linetype = "dotted")
qqPlot <- qqPlot + xlab("Expected Quantile") + ylab("Observed Quantile")
plot(qqPlot)
```

It is possible to make the same plot for the observed and expected p-values, based on these quantiles. The red dots show a tolerated deviation ratio of from the expected p-values as set in the _ppTolerance_ variable. Note that the measured p-values deviate from the diagonal at low p-values, indicating that our dataset does not fully satisfy the hypotheses of the t-test.

```{r pp_plot}

ppTolerance <-1.1

expectedPValues <- pt(expectedQuantiles, lower.tail = expectedQuantiles < 0, df=degreesOfFreedom)
expectedPValues <- sort(expectedPValues)
expectedPValuesLog <- -log10(expectedPValues)
measuredPValues <- validProteinGroupsRatios$tTestPValue
measuredPValues <- sort(measuredPValues)
measuredPValuesLog <- -log10(measuredPValues)

limitLow <- expectedPValues/ppTolerance
limitLow <- -log10(limitLow)
limitHigh <- ppTolerance * expectedPValues
limitHigh <- -log10(limitHigh)

ppPlot <- ggplot()
ppPlot <- ppPlot + geom_point(aes(x=expectedPValuesLog, y=measuredPValuesLog), size = 1, col = "blue")
ppPlot <- ppPlot + geom_line(aes(x=expectedPValuesLog, y=expectedPValuesLog), size = 1, alpha = 0.5, linetype = "dashed", col="black")
ppPlot <- ppPlot + geom_line(aes(x=expectedPValuesLog, y=limitLow), size = 1, alpha = 0.5, linetype = "dotted", col="red")
ppPlot <- ppPlot + geom_line(aes(x=expectedPValuesLog, y=limitHigh), size = 1, alpha = 0.5, linetype = "dotted", col="red")
ppPlot <- ppPlot + xlab("Expected p-value [-log10(p)]") + ylab("Observed p-value [-log10(p)]")
plot(ppPlot)
```

We calculate lambda as the ratio of the observed p-value and the expected p-value. A density plot shows that the majority of the p-values are within a `r ppTolerance` deviation ratio.

```{r hist_lambda}

lambda <- measuredPValues/expectedPValues
lambdaLog <- log(lambda, base = ppTolerance)

lambdaHistogramPlot <- ggplot()
lambdaHistogramPlot <- lambdaHistogramPlot + geom_density(aes(x=lambdaLog), col="blue", fill = "blue", alpha = 0.1)
lambdaHistogramPlot <- lambdaHistogramPlot + geom_vline(aes(xintercept=-1), col="red", alpha = 0.8, linetype="dotted")
lambdaHistogramPlot <- lambdaHistogramPlot + geom_vline(aes(xintercept=1), col="red", alpha = 0.8, linetype="dotted")
lambdaHistogramPlot <- lambdaHistogramPlot + xlab(paste("Lambda (Observed p-value / Expected p-value) [log", ppTolerance, "]", sep="")) + ylab("Density of proteins")
plot(lambdaHistogramPlot)

corePopulation <- round(100*length(lambdaLog[abs(lambdaLog) < 1])/length(lambdaLog))/100
```

`r 100*corePopulation`% of the p-values is contained within the `r ppTolerance` deviation ratio. This percentile will be used in the following as core population.

## Multiple hypothesis testing

The more we run t-tests, the more chances we have to get a low p-value by chance. For example, when we run the test just one time, we are unlikely to find a p < 1% by chance, whereas if we run the test 100 times, we are likely to find at least one p < 1% by chance. This problem is called the multiple hypothesis testing.

It is possible to adjust the p-values to correct for multiple hypothesis testing. This can be done using the `p.adjust` function of the stats package. Note that numerous methods were established to correct for multiple hypothesis testing. The simplest approach is to multiply the p-values by the number of tests, called a _Bonferroni_ correction. It is also possible to control the expected share of incorrect findings among the significant results, a False Discovery Rate (FDR). This is called a Benjamini and Hochberg correction, "BH", [(6)](#references).

```{r bh_plot}

validProteinGroupsRatios$bonferroniPValue <- p.adjust(validProteinGroupsRatios$tTestPValue, method = "bonferroni")
validProteinGroupsRatios$bhFDR <- p.adjust(validProteinGroupsRatios$tTestPValue, method = "BH")

bhPlot <- ggplot()
bhPlot <- bhPlot + geom_line(aes(x=validProteinGroupsRatios$tTestPValueLog, 100 * validProteinGroupsRatios$bonferroniPValue), col="red", alpha = 0.8)
bhPlot <- bhPlot + geom_line(aes(x=validProteinGroupsRatios$tTestPValueLog, 100 * validProteinGroupsRatios$bhFDR), col="blue", alpha = 0.8)
bhPlot <- bhPlot + xlab("Original p-value") + ylab("Bonferroni p-value [%] (red) - BH FDR [%] (blue)")
plot(bhPlot)
```

According to these two methods, no result can be retained accounting for multiple hypothesis testing.


## Independent weighting hypothesis

The following code shows the histogram of fold changes between diagnostic and relapse for all proteins, as estimated in the t-test section by the difference between the median value of relapse cell lines compaired to the median value of diagnostic cell lines. The red line shows a normal distribution with mean and standard deviation calibrated on the median and the 34th percentiles around the median, respectively.

```{r fc_histogram}
nBinsInOne <- 10
binSize <- 1/nBinsInOne
minFC <- floor(min(validProteinGroupsRatios$fc))
maxFC <- ceiling(max(validProteinGroupsRatios$fc))

quantilesFC <- quantile(validProteinGroupsRatios$fc, c(0.16, 0.5, 0.84), na.rm = T, names = F)
medianFC <- quantilesFC[2]
interQuantilesFC <- quantilesFC[3] - quantilesFC[1]
xDistribution <- minFC + (binSize * (1:(nBinsInOne * (maxFC - minFC))))
yDistribution <- dnorm(x = xDistribution, mean = medianFC, sd = interQuantilesFC/2)
scale <- length(validProteinGroupsRatios$fc)/nBinsInOne
yDistributionNorm <- scale * yDistribution

fcHistogramPlot <- ggplot()
fcHistogramPlot <- fcHistogramPlot + geom_histogram(aes(x=validProteinGroupsRatios$fc), col="blue", fill = "blue", alpha = 0.1, binwidth = binSize)
fcHistogramPlot <- fcHistogramPlot + geom_line(aes(x=xDistribution, yDistributionNorm), col="red", alpha = 0.8)
fcHistogramPlot <- fcHistogramPlot + xlab("Fold Change") + ylab("Number of proteins")
plot(fcHistogramPlot)
```

With the hypothesis that false positives introduced by multiple hypothesis testing are likely to distribute according to the rest of the fold changes, independently of the p-value, we can use the fold change as independent weighting hypothesis (IWH) to spread the hits on another dimension. The resulting plot is called a _volcano plot_.

The proteins on the upper side of the plot are the ones with the lowest p-value (note the inverted log10 scale). In order to avoid false positives, we are going to require these significant hits to have a high fold change. One typically uses a fold change of 2 (note the log2 scale).

```{r volcano_plot}

pLimit <- 0.05
pLimitLog <- -log10(pLimit)
regulationConfidence <- character(length(validProteinGroupsRatios$tTestPValueLog))
regulationConfidence <- ifelse(validProteinGroupsRatios$tTestPValue < pLimit, "Significant but not Differentially Expressed", "Not Significant")
regulationConfidence <- ifelse(validProteinGroupsRatios$tTestPValue < pLimit & abs(validProteinGroupsRatios$fc) > 1, "Differentially Expressed", regulationConfidence)

volcanoPlot <- ggplot()
volcanoPlot <- volcanoPlot + geom_point(aes(x=validProteinGroupsRatios$fc, y=validProteinGroupsRatios$tTestPValueLog, col=regulationConfidence), size = 1, alpha = 0.5)
volcanoPlot <- volcanoPlot + geom_hline(aes(yintercept = pLimitLog), col="blue", alpha = 0.8, linetype="dotted", size = 1)
volcanoPlot <- volcanoPlot + geom_vline(aes(xintercept = -1), col="blue", alpha = 0.8, linetype="dotted", size = 1)
volcanoPlot <- volcanoPlot + geom_vline(aes(xintercept = 1), col="blue", alpha = 0.8, linetype="dotted", size = 1)
volcanoPlot <- volcanoPlot + scale_color_manual(values=c("darkgreen", "darkRed", "darkorange"), name="Protein Category")
volcanoPlot <- volcanoPlot + xlab("Fold Change [log2]") + ylab("p-value [-log(p)]")
plot(volcanoPlot)
```

Note that in contrary to the previous method, we are using arbitrary thresholds and we have no control on the error rate. A control of the error rate using IHW can be done using the [IHW package](http://bioconductor.org/packages/devel/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html) of bioconductor.

## Missing values imputation

For the following, we are going to impute the missing values and assign them the value 0.

```{r missing_values}
for (i in 1:length(diagnosisCellLines)) {
  validProteinGroupsRatios[,diagnosisCellLines[i]] <- ifelse(is.na(validProteinGroupsRatios[,diagnosisCellLines[i]]), 0, validProteinGroupsRatios[,diagnosisCellLines[i]])
}
for (i in 1:length(relapseCellLines)) {
  validProteinGroupsRatios[,relapseCellLines[i]] <- ifelse(is.na(validProteinGroupsRatios[,relapseCellLines[i]]), 0, validProteinGroupsRatios[,relapseCellLines[i]])
}
```


## Principal component analysis 

We will now draw a principal component analysis (PCA) plot.

```{r pca}

pcaInput <- data.frame(validProteinGroupsRatios$molm13, 
                       validProteinGroupsRatios$mv411, 
                       validProteinGroupsRatios$nb4, 
                       validProteinGroupsRatios$ociAml3, 
                       validProteinGroupsRatios$thp1)
pca <- prcomp(pcaInput)
pc1 <- pca$rotation[,1]
pc2 <- pca$rotation[,2]
totalStd <- sum(pca$sdev)
contribution1 <- round(100*pca$sdev[1]/totalStd)
contribution2 <- round(100*pca$sdev[2]/totalStd)
names <- names(validProteinGroupsRatios)[2:6]

pcaPlot <- ggplot()
pcaPlot <- pcaPlot + geom_point(aes(x=pc1, y=pc2, col=names))
pcaPlot <- pcaPlot + xlab(paste("PC1 [", contribution1, "%]", sep=""))
pcaPlot <- pcaPlot + ylab(paste("PC2 [", contribution2, "%]", sep=""))
plot(pcaPlot)
```




## References

(1) [MaxQuant enables high peptide identification rates, individualized p.p.b. range mass accuracies and proteome-wide protein quantification](https://www.ncbi.nlm.nih.gov/pubmed/19029910)
(3) [ProteomeXchange provides globally coordinated proteomics data submission and dissemination](https://www.ncbi.nlm.nih.gov/pubmed/24727771)
(4) [PRIDE: the proteomics identifications database](https://www.ncbi.nlm.nih.gov/pubmed/16041671)

(3) [Geiger, T. _et al._, _Super-SILAC mix for quantitative proteomics of human tumor tissue_, Nature Methods, 2010](https://www.ncbi.nlm.nih.gov/pubmed/20364148)

(5) [Aasebo, E. _et al._, _Performance of super-SILAC based quantitative proteomics for comparison of
different acute myeloid leukemia (AML) cell lines_, Proteomics, 2014](https://www.ncbi.nlm.nih.gov/pubmed/25044641)
(6) [Benjamini, Y. and Hochberg, Y., _Controlling the false discovery rate: a practical and powerful approach to multiple testing_, Journal of the Royal Statistical Society, 1995](http://www.math.tau.ac.il/~ybenja/MyPapers/benjamini_hochberg1995.pdf)
